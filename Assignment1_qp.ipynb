{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rational-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "inappropriate-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read corpus and transform to list \n",
    "corpus_a_path = 'corpus_a.txt'\n",
    "corpus_b_path = 'corpus_b.txt'\n",
    "stopwords_path = 'stopwords.txt'\n",
    "\n",
    "with open(corpus_a_path,'r',encoding='utf-8') as a:\n",
    "    word_a = a.read().split()\n",
    "with open(corpus_b_path,'r',encoding='utf-8') as b:\n",
    "    word_b = b.read().split()\n",
    "with open(stopwords_path,'r',encoding='utf-8') as s:\n",
    "    stop = s.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "numerical-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5(word_a):\n",
    "    a_dict = dict(Counter(word_a))\n",
    "    \n",
    "    # 5.1 p('united')\n",
    "    p1 = a_dict['united'] / len(word_a)\n",
    "    print(\"p('united') =\", p1)\n",
    "    \n",
    "    # 5.2 p('united kingdom')\n",
    "    cnt = 0\n",
    "    for i in range(len(word_a) - 1):\n",
    "        if word_a[i] == 'united' and word_a[i + 1] == 'kingdom':\n",
    "            cnt += 1;\n",
    "    p2 = cnt / (len(word_a) - 1)\n",
    "    print(\"p('united kingdom') =\", p2)\n",
    "    \n",
    "    # 5.3 p('kingdom | united')\n",
    "    p3 = p2 / p1 # since P(B|A) = P(A and B) / P(A)\n",
    "    print(\"p('kingdom | united') =\", p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "medieval-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(p):\n",
    "    return -p * np.log2(p)\n",
    "\n",
    "def get_interset(word_a, word_b):\n",
    "    ab_inter = list(set(word_a).intersection(word_b))  # contains items that in overlapping section  \n",
    "    a_dict = dict(Counter(word_a))\n",
    "    b_dict = dict(Counter(word_b))\n",
    "    alen_inter, blen_inter = 0, 0\n",
    "    for x in ab_inter:\n",
    "        alen_inter += a_dict[x]  # the number of item in word_a enter the overlapping section \n",
    "        blen_inter += b_dict[x]  # the number of item in word_b enter the overlapping section\n",
    "    return ab_inter, alen_inter, blen_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "constitutional-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question6(word_a, word_b):\n",
    "    \n",
    "    a_dict = dict(Counter(word_a))\n",
    "    b_dict = dict(Counter(word_b))\n",
    "    \n",
    "    a_entropy, b_entropy = 0, 0\n",
    "    for i in a_dict:\n",
    "        p = a_dict[i] / len(word_a)\n",
    "        a_entropy += get_entropy(p)\n",
    "    for i in b_dict:\n",
    "        p = b_dict[i] / len(word_b)\n",
    "        b_entropy += get_entropy(p)\n",
    "    \n",
    "    # 6.1 6.2 word-based entropy of corpus_a.txt, corpus_b.txt\n",
    "    print(\"H(X) =\", a_entropy)\n",
    "    print(\"H(Y) =\", b_entropy)\n",
    "    \n",
    "    # 6.3 word-based entropy of the combination of corpus_a.txt and corpus_b.txt\n",
    "    print(\"######if Z is union_set######\")\n",
    "    ab_union = word_a + word_b\n",
    "    z_dict = dict(Counter(ab_union))\n",
    "    z_entropy_union = 0\n",
    "    for i in z_dict:\n",
    "        p = z_dict[i] / len(word_z)\n",
    "        z_entropy_union += get_entropy(p)\n",
    "    print(\"H(Z) =\", z_entropy_union)\n",
    "    \n",
    "    print(\"######if Z is intersect_set######\")\n",
    "    ab_inter, alen_inter, blen_inter = get_interset(word_a, word_b)\n",
    "    z_entropy_inter = 0\n",
    "    for x in ab_inter:\n",
    "        p = (a_dict[x] + b_dict[x]) / (alen_inter + blen_inter)\n",
    "        z_entropy_inter += get_entropy(p)\n",
    "    print(\"H(Z) =\", z_entropy_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question7(word_a, word_b, stop):\n",
    "    print(\"##########if Z is union_set##########\")\n",
    "    z_union = word_a + word_b\n",
    "    z_dict = dict(Counter(z_union))\n",
    "\n",
    "    ab_union_filter = list(filter(lambda x: x not in stop, z_union))\n",
    "    z_filter_dict = dict(Counter(ab_union_filter))\n",
    "\n",
    "    # filter\n",
    "    sum_filter, sum_not_filter = 0, 0\n",
    "    for x in z_filter_dict:\n",
    "        pz_filter = z_filter_dict[x] / len(ab_union_filter)\n",
    "        sum_filter += get_entropy(0.5 * pz_filter)\n",
    "\n",
    "    # not filter\n",
    "    for x in z_dict:\n",
    "        pz = z_dict[x] / len(ab_union)\n",
    "        sum_not_filter += get_entropy(0.5 * pz)\n",
    "    H_AZ = sum_filter + sum_not_filter\n",
    "    print('H_AZ', H_AZ)\n",
    "    H_A = -np.log2(0.5)\n",
    "    H_Z_given_A = H_AZ - H_A\n",
    "    print(\"H(A|Z)\", H_Z_given_A)\n",
    "\n",
    "    print(\"#########if Z is intersect set############\")\n",
    "    ab_inter, alen_inter, blen_inter = get_interset(word_a, word_b)# inter_word\n",
    "    ab_inter_filter = list(filter(lambda x: x not in stop, ab_inter))  # inter_wordï¼Œfilter stopwords\n",
    "\n",
    "    a_dict = dict(Counter(word_a))\n",
    "    b_dict = dict(Counter(word_b))\n",
    "\n",
    "    # filter stop\n",
    "    alen_inter_f, blen_inter_f = 0, 0\n",
    "    for x in ab_inter_filter:\n",
    "        alen_inter_f += a_dict[x]\n",
    "        blen_inter_f += b_dict[x]\n",
    "\n",
    "    sum_filter = 0\n",
    "    for x in ab_inter_filter:\n",
    "        pz = (a_dict[x] + b_dict[x]) / (alen_inter_f + blen_inter_f)\n",
    "        sum_filter += 0.5 * pz * np.log2(0.5 * pz)\n",
    "\n",
    "    # not filter stop\n",
    "    sum_not_filter = 0\n",
    "    for x in ab_inter:\n",
    "        pz = (a_dict[x] + b_dict[x]) / (alen_inter + blen_inter)\n",
    "        sum_not_filter += 0.5 * pz * np.log2(0.5 * pz)\n",
    "\n",
    "    H_AZ = -sum_filter - sum_not_filter\n",
    "    print('H_AZ', H_AZ)\n",
    "    H_A = -np.log2(0.5)\n",
    "    H_Z_given_A = H_AZ - H_A\n",
    "    print(\"H(A|Z)\", H_Z_given_A)\n",
    "\n",
    "    ## 3,4\n",
    "    item1, item2 = 0, 0\n",
    "    for x in ab_inter:\n",
    "        pa = a_dict[x] / alen_inter\n",
    "        pb = b_dict[x] / blen_inter\n",
    "        item1 += pa * np.log2(pa)\n",
    "        item2 += pa * np.log2(pb)\n",
    "\n",
    "    print('KL', item1 - item2)\n",
    "    print('XE', -item2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
